{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='img/vector.png' style='height:200px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "### Representaci√≥n vectorial de textos (Parte 1)\n",
    "#### NLP - Anal√≠tica Estrat√©gica de Datos\n",
    "<br><b>Fundaci√≥n Universitaria Konrad Lorenz</b>\n",
    "<br>Docente: Viviana M√°rquez [vivianam.penam@konradlorenz.edu.co](mailto:vivianam.penam@konradlorenz.edu.co)\n",
    "<br>Clase #4: Septiembre 4, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Retroalimentaci√≥n Taller 2\n",
    "\n",
    "# Retroalimentaci√≥n Taller 3\n",
    "\n",
    "(Al final de la clase... 10 minutos de bucles y otras cosas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ‚åõ En la clase anterior\n",
    "\n",
    "Herramientas de pre-procesamiento de texto en NLP\n",
    "\n",
    "- Stop Words (Palabras vac√≠as)\n",
    "- Tokenization (Tokenizaci√≥n)\n",
    "- Stemming (Ra√≠z)\n",
    "- Lemmatization (Lematizaci√≥n)\n",
    "- POS tagging (Etiquetado gramatical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Flujo de datos en un proyecto de NLP (pipeline)\n",
    "\n",
    "<br><center><img src='img/pipeline.png'><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Flujo de datos en un proyecto de NLP (pipeline) --- En clases anteriores\n",
    "\n",
    "<br><center><img src='img/pipeline1.png'><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Flujo de datos en un proyecto de NLP (pipeline) --- En clases anteriores\n",
    "\n",
    "<br><center><img src='img/pipeline2.png'><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Flujo de datos en un proyecto de NLP (pipeline) --- Hoy\n",
    "\n",
    "<br><center><img src='img/pipeline3.png'><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üöÄ Hoy veremos...\n",
    "\n",
    "- Repaso de Feature Engineering en Machine Learning \n",
    "- Representaci√≥n de datos en forma num√©rica\n",
    "- Espacio sem√°ntico vectorial\n",
    "- M√©todos de vectorizaci√≥n\n",
    "    - One-Hot Encoding \n",
    "    - Bag of Words\n",
    "    - Bag of N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Engineering ([1](https://developers.google.com/machine-learning/glossary)) ([2](https://github.com/omar-florez/AI_Dictionary_English_Spanish/blob/master/release/AI_Dictionary.pdf))\n",
    "\n",
    "<br><center><img src='img/FEng1.jpg' style='height:500px;'></center>\n",
    "    \n",
    "- Es el proceso de usar el conocimiento del dominio para crear atributos que sirvan para entrenar un modelo de aprendizaje autom√°tico. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- <i>\"Garbage in, garbage out\"</i> -- Malos atributos, malos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align='center'>\n",
    "    <img src='img/FEng1.jpg' style='height:500px; float: left; margin: 0px 15px 15px 0px'>\n",
    "    <img src='img/FEng2.jpg' style='height:500px; float: left; margin: 0px 15px 15px 0px'>\n",
    "</div>\n",
    "\n",
    "- Podemos cambiar de un sistema cartesiano $(x,y)$ a un sistema polar $(r,\\theta)$ con una simple transformaci√≥n de coordenadas: $$r = \\sqrt{x^2 + y^2} \\Rightarrow \\theta = \\tan^{-1} \\left(\\dfrac{y}{x}\\right)$$\n",
    "- Ahora vemos que es f√°cil dividir el conjunto usando $r=2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Otros ejemplos de Feature Engineering \n",
    "\n",
    "- Atributos categ√≥ricos-- Ejemplo: G√©nero, edad (cubetas), raza(variable ficticia)\n",
    "- Datos continuos\n",
    "- Valores faltantes\n",
    "- Normalizaci√≥n\n",
    "- Fechas\n",
    "- **Feature engineering para NLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Engineering para NLP\n",
    "\n",
    "<img src='img/FEngNLP.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representaci√≥n de datos en forma num√©rica\n",
    "\n",
    "**Ejemplo: Im√°genes**\n",
    "\n",
    "<center><img src='img/komp.jpg'></center>\n",
    "\n",
    "- Una imagen es representada en un computador en la forma de una matriz donde cada $celda[i,j]$ representa el p√≠xel $i,j$ de la imagen.<br>\n",
    "\n",
    "- De manera similar, un video es una colecci√≥n de fotogramas, donde cada fotograma es una im√°gen. Por lo tanto, cualquier video puede ser representado como una colecci√≥n de matrices. <br>\n",
    "\n",
    "- (Des)afortunadamente, representar texto  de manera num√©rica no es tan sencillo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Espacio sem√°ntico vectorial\n",
    "\n",
    "- Las redes neuronales pueden hacer que las m√°quinas entiendan las analog√≠as como los humanos [Mikolov et al., 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 s, sys: 857 ms, total: 27.5 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Useful functions\n",
    "def load_glove(filename):\n",
    "    dic = {}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            vec = line.split()\n",
    "            dic[vec[0]]= np.array(vec[1:], dtype=float)\n",
    "    return dic\n",
    "\n",
    "def analogies(gloves, x, y, z, n):\n",
    "    dif_1 = gloves[x] - gloves[y]\n",
    "    distances=[]\n",
    "    for key,val in gloves.items():\n",
    "        if z!=key:\n",
    "            dif_2 = gloves[z]-gloves[key]\n",
    "            distances.append((np.linalg.norm(dif_1-dif_2),key))\n",
    "    distances.sort()\n",
    "    return [d[1] for d in distances[0:n]]\n",
    "\n",
    "gloves = load_glove(\"archivos/glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def print_analogy():\n",
    "    print(\"Enter a word or 'x:y as z:'\")\n",
    "    cmd = input(\"> \")\n",
    "\n",
    "    while cmd!=None:\n",
    "        try:  \n",
    "            match = re.search(r'(\\w+):(\\w+) as (\\w+):', cmd)\n",
    "            x = match.group(1).lower()\n",
    "            y = match.group(2).lower()\n",
    "            z = match.group(3).lower()\n",
    "\n",
    "            words = analogies(gloves, x, y, z, 5)\n",
    "\n",
    "            print(\"%s is to %s as %s is to {%s}\" % (x,y,z,' '.join(words)))\n",
    "            cmd = input(\"> \")\n",
    "        except:\n",
    "            print(\"Bye mis cielas!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print_analogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¬øQu√© hay bajo el cap√≥?\n",
    "\n",
    "<br>\n",
    "<center><img src='img/brain.jpg' style='height:300px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Imaginemos que todas las palabras y sus significados viven en un espacio de altas dimensiones. Nosotros lo llam√°remos **espacio sem√°ntico vectorial**<br>\n",
    "\n",
    "- Cada dimensi√≥n en el espacio sem√°ntico vectorial representa alg√∫n aspecto del significado de la palabra\n",
    "\n",
    "- Los conceptos y las palabras que significan cosas similares deben vivir cerca en este espacio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¬øC√≥mo sabemos qu√© significa una palabra?\n",
    "\n",
    "<br>\n",
    "<center><img src='img/reina.jpg' style='height:500px; float: center; margin: 0px 15px 15px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nosotros aprendemos a trav√©s de la experiencia\n",
    "\n",
    "<br>\n",
    "<center><img src='img/reyes2.png' style='height:500px; float: center; margin: 0px 15px 15px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Las m√°quinas tambi√©n aprenden a trav√©s de la experiencia\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='img/maquina1.png' style='height:500px; float: left; margin: 0px 15px 15px 0px'>\n",
    "    <img src='img/maquina2.png' style='height:500px; float: left; margin: 0px 15px 15px 0px'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¬øQu√© hay bajo el cap√≥? Representaci√≥n num√©rica de textos\n",
    "\n",
    "<center><img src='img/espacio.jpg' style='height:500px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "<center><big><b>¬°Matem√°ticas!</center></big></b>\n",
    "\n",
    "<br>\n",
    "\n",
    "- siginificado($man$) - significado($king$) + significado($queen$) = significado($woman$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representaci√≥n vectorial de textos\n",
    "\n",
    "- Existen varios m√©todos\n",
    "- Lo que diferencia un m√©todo del otro es qu√© tan bien captura las propiedades ling√º√≠sticas del texto que representa y la cantidad de espacio que ocupa en memoria\n",
    "<br><br>\n",
    "- **M√©todos m√°s populares**:\n",
    "    - One-Hot Encoding \n",
    "    - Bag of Words (Bolsa de palabras)\n",
    "    - Bag of N-Grams (Bolsa de n-gramas)\n",
    "    - TF-IDF\n",
    "    - Word embeddings (word2vec)\n",
    "    - CBOW (Bolsa de palabras continua)\n",
    "    - SkipGram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " #### (Par√©ntisis)\n",
    " \n",
    "**Corpus ling√º√≠stico**: Conjunto amplio y estructurado de ejemplos reales de uso de la lengua.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## üõ†Ô∏è One-Hot Encoding\n",
    " \n",
    " Mapear cada palabra en el vocabulario del corpus de texto a una identificaci√≥n √∫nica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>D1</td>\n",
       "      <td>perro muerde hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D2</td>\n",
       "      <td>hombre muerde perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D3</td>\n",
       "      <td>perro come carne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D4</td>\n",
       "      <td>hombre come comida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  texto\n",
       "D1  perro muerde hombre\n",
       "D2  hombre muerde perro\n",
       "D3     perro come carne\n",
       "D4   hombre come comida"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = {'D1': 'perro muerde hombre',\n",
    "          'D2': 'hombre muerde perro',\n",
    "          'D3': 'perro come carne',\n",
    "          'D4': 'hombre come comida'}\n",
    "\n",
    "corpus = pd.DataFrame.from_dict(corpus, orient='index', columns=['texto'])\n",
    "\n",
    "corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('come', 1), ('perro', 2), ('muerde', 3), ('hombre', 4), ('carne', 5), ('comida', 6)]\n"
     ]
    }
   ],
   "source": [
    "vocabulario = corpus.texto.str.cat(sep=\" \")\n",
    "vocabulario = set(vocabulario.split())\n",
    "vocabulario = [(palabra,i+1) for i,palabra in enumerate(vocabulario)]\n",
    "    \n",
    "print(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra: come\n",
      "One-hot encoding: [1 0 0 0 0 0]\n",
      "\n",
      "Palabra: perro\n",
      "One-hot encoding: [0 1 0 0 0 0]\n",
      "\n",
      "Palabra: muerde\n",
      "One-hot encoding: [0 0 1 0 0 0]\n",
      "\n",
      "Palabra: hombre\n",
      "One-hot encoding: [0 0 0 1 0 0]\n",
      "\n",
      "Palabra: carne\n",
      "One-hot encoding: [0 0 0 0 1 0]\n",
      "\n",
      "Palabra: comida\n",
      "One-hot encoding: [0 0 0 0 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_onehot = np.array([[0]*len(vocabulario)]*len(vocabulario))\n",
    "\n",
    "for palabra,i in vocabulario:\n",
    "    vocab_onehot[i-1,i-1] = 1\n",
    "    print(f\"Palabra: {palabra}\")\n",
    "    print(f\"One-hot encoding: {vocab_onehot[i-1,:]}\")\n",
    "    print()\n",
    "    \n",
    "vocab_onehot = pd.DataFrame(vocab_onehot) \n",
    "vocab_onehot.columns = [palabra[0] for palabra in vocabulario]\n",
    "vocab_onehot.index = [palabra[0] for palabra in vocabulario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(frase):\n",
    "    frase_onehot = []\n",
    "    for palabra in frase.split():\n",
    "        frase_onehot.append(vocab_onehot[palabra].tolist())\n",
    "    print(frase_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoder(\"perro muerde hombre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Ventajas\n",
    "- Es intuitivo y f√°cil de entender\n",
    "- La implementaci√≥n es directa\n",
    "\n",
    "#### Desventajas\n",
    "- Genera una matriz dispersa\n",
    "- El vector de cada frase no tiene un tama√±o constante\n",
    "- No tiene noci√≥n de similitud entre palabras\n",
    "- Problema de fuera de vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## üõ†Ô∏è Bag of Words (BoW) -- Bolsa de Palabras\n",
    " \n",
    "- Representar el texto como una bolsa de palabras (ignorando orden y contexto) \n",
    "- Si dos piezas de texto tienen casi las mismas palabras, entonces pertenecen a la misma bolsa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('come', 1), ('perro', 2), ('muerde', 3), ('hombre', 4), ('carne', 5), ('comida', 6)]\n"
     ]
    }
   ],
   "source": [
    "print(vocabulario) # Sigue siendo el mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def bow(frase):\n",
    "    frase_bow = [0]*len(vocabulario)\n",
    "    for palabra,i in vocabulario:\n",
    "        if palabra in frase.split():\n",
    "            frase_bow[i-1] = 1\n",
    "    print(frase_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "bow(\"perro muerde hombre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "bow(\"perro muerde hombre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(\"perro muerde hombre\")\n",
    "\n",
    "np.sum(np.array([[0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0]]),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='img/bebememe.png' style='height:500px; float: center; margin: 0px 15px 15px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-learn \n",
    "\n",
    "- Es una biblioteca para aprendizaje autom√°tico de software libre para el lenguaje de programaci√≥n Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario:  {'perro': 5, 'muerde': 4, 'hombre': 3, 'come': 1, 'carne': 0, 'comida': 2}\n",
      "Representaci√≥n BoW de 'perro muerde hombre':  [[0 0 0 1 1 1]]\n",
      "Representaci√≥n BoW de 'hombre muerde perro':  [[0 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "bow_rep = count_vect.fit_transform(corpus.texto.values)\n",
    "\n",
    "print(\"Vocabulario: \", count_vect.vocabulary_)\n",
    "\n",
    "print(\"Representaci√≥n BoW de 'perro muerde hombre': \", bow_rep[0].toarray())\n",
    "print(\"Representaci√≥n BoW de 'hombre muerde perro': \", bow_rep[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representaci√≥n BoW: 'perro y perro son amigos': [[0 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "temp = count_vect.transform([\"perro y perro son amigos\"])\n",
    "print(\"Representaci√≥n BoW: 'perro y perro son amigos':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si no nos importa la frecuencia, `binary=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representaci√≥n BoW de 'perro muerde hombre':  [[0 0 0 1 1 1]]\n",
      "Representaci√≥n BoW: 'perro y perro son amigos': [[0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(binary=True)\n",
    "bow_rep = count_vect.fit_transform(corpus.texto.values)\n",
    "print(\"Representaci√≥n BoW de 'perro muerde hombre': \", bow_rep[0].toarray())\n",
    "\n",
    "temp = count_vect.transform([\"perro y perro son amigos\"])\n",
    "print(\"Representaci√≥n BoW: 'perro y perro son amigos':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Ventajas\n",
    "- Es intuitivo y f√°cil de entender\n",
    "- La implementaci√≥n es directa\n",
    "- El vector de cada frase tiene un tama√±o constante\n",
    "\n",
    "#### Desventajas\n",
    "- Genera una matriz dispersa (¬øsoluci√≥n?)\n",
    "- No tiene noci√≥n de similitud entre palabras\n",
    "- Problema de fuera de vocabulario\n",
    "- Se pierde el orden de la informaci√≥n\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "M√©todo bastante usado en la industria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## üõ†Ô∏è Bag of N-Grams (BoN) -- Bolsa de n-gramas\n",
    " <br>\n",
    " <center><img src='img/NY.jpg' style='height:300px; float: center; margin: 0px 15px 15px 0px'>\n",
    "     https://pollev.com/vivianamarqu288</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Hasta el momento solo hemos visto las palabras como unidades independientes\n",
    "- Con la bolsa de n-gramas capturamos un poco de contexto y orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>D1</td>\n",
       "      <td>perro muerde hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D2</td>\n",
       "      <td>hombre muerde perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D3</td>\n",
       "      <td>perro come carne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D4</td>\n",
       "      <td>hombre come comida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  texto\n",
       "D1  perro muerde hombre\n",
       "D2  hombre muerde perro\n",
       "D3     perro come carne\n",
       "D4   hombre come comida"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario:  {'perro': 11, 'muerde': 8, 'hombre': 5, 'perro muerde': 13, 'muerde hombre': 9, 'hombre muerde': 7, 'muerde perro': 10, 'come': 1, 'carne': 0, 'perro come': 12, 'come carne': 2, 'comida': 4, 'hombre come': 6, 'come comida': 3}\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "bow_rep = count_vect.fit_transform(corpus.texto.values)\n",
    "print(\"Vocabulario: \", count_vect.vocabulary_)\n",
    "print(\"Representaci√≥n BoW de 'perro muerde hombre': \", bow_rep[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Ventajas\n",
    "- Captura alguna informaci√≥n sobre el contexto y orden\n",
    "\n",
    "#### Desventajas\n",
    "- Genera una matriz dispersa ¬°r√°pidamente!\n",
    "- Problema de fuera de vocabulario\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "[M√°s sobre n-gramas](https://nlp.stanford.edu/fsnlp/promo/colloc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü§ì Recapitulando: Hoy aprend√≠mos...\n",
    "\n",
    "- Repaso de Feature Engineering en Machine Learning\n",
    "- Representaci√≥n de datos en forma num√©rica\n",
    "- Espacio sem√°ntico vectorial\n",
    "- M√©todos de vectorizaci√≥n\n",
    "    - One-Hot Encoding\n",
    "    - Bag of Words\n",
    "    - Bag of N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¬°Tiempo de taller!\n",
    "\n",
    "<center>\n",
    "<img src='img/Taller.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Taller # 4:** Representaci√≥n vectorial de textos (Parte 1)\n",
    "\n",
    "**Fecha de entrega:** Septiembre 12, 2020. (Antes del inicio de la pr√≥xima clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src='img/fin.gif'>\n",
    "\n",
    "### Proxima clase(s): Representaci√≥n vectorial de textos (Parte 2)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
